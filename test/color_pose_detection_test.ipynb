{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img, name):\n",
    "    cv2.imshow(f'{name}', img)\n",
    "    cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows() simply destroys all the windows we created.\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"test.jpg\")\n",
    "\n",
    "showImage(img, \"Show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe_filter = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "grayimg = gray\n",
    "\n",
    "GLARE_MIN = np.array([0, 0, 60],np.uint8)\n",
    "GLARE_MAX = np.array([0, 0, 215],np.uint8)\n",
    "\n",
    "hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#HSV\n",
    "frame_threshed = cv2.inRange(hsv_img, GLARE_MIN, GLARE_MAX)\n",
    "#INPAINT\n",
    "mask1 = cv2.threshold(grayimg , 220, 255, cv2.THRESH_BINARY)[1]\n",
    "result1 = cv2.inpaint(img, mask1, 0.1, cv2.INPAINT_TELEA)\n",
    "\n",
    "showImage(result1, 'Inpaint')\n",
    "\n",
    "#CLAHE\n",
    "claheCorrecttedFrame = clahe_filter.apply(grayimg)\n",
    "\n",
    "#Color\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "L, A, B = cv2.split(lab)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
    "L = clahe.apply(L)\n",
    "lab = cv2.merge((L, A, B))\n",
    "clahe_bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "showImage(clahe_bgr, 'clahe_bgr')\n",
    "\n",
    "#INPAINT + HSV\n",
    "result = cv2.inpaint(img, frame_threshed, 0.1, cv2.INPAINT_TELEA) \n",
    "showImage(result, 'Inpaint+HSV')\n",
    "\n",
    "#INPAINT + CLAHE\n",
    "grayimg1 = cv2.cvtColor(clahe_bgr, cv2.COLOR_BGR2GRAY)\n",
    "mask2 = cv2.threshold(grayimg1 , 220, 255, cv2.THRESH_BINARY)[1]\n",
    "result2 = cv2.inpaint(img, mask2, 0.1, cv2.INPAINT_TELEA) \n",
    "\n",
    "#HSV+ INPAINT + CLAHE\n",
    "lab1 = cv2.cvtColor(result, cv2.COLOR_BGR2LAB)\n",
    "L1, A1, B1 = cv2.split(lab1)\n",
    "clahe1 = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
    "L1 = clahe1.apply(L1)\n",
    "lab1 = cv2.merge((L1, A1, B1))\n",
    "clahe_bgr1 = cv2.cvtColor(lab1, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# display it\n",
    "cv2.imshow(\"IMAGE\", img)\n",
    "cv2.imshow(\"GRAY\", gray)\n",
    "cv2.imshow(\"HSV\", frame_threshed)\n",
    "cv2.imshow(\"CLAHE\", clahe_bgr)\n",
    "cv2.imshow(\"LAB\", lab)\n",
    "cv2.imshow(\"HSV + INPAINT\", result)\n",
    "cv2.imshow(\"INPAINT\", result1)\n",
    "cv2.imshow(\"CLAHE + INPAINT\", result2)  \n",
    "cv2.imshow(\"HSV + INPAINT + CLAHE   \", clahe_bgr1)\n",
    "\n",
    "\n",
    "# Break with esc key\n",
    "cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows() simply destroys all the windows we created.\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = result1\n",
    "SIL_LOW = np.array([0,60, 100])\n",
    "SIL_HIGH = np.array([255, 255, 255])\n",
    "hsv_frame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_frame, SIL_LOW, SIL_HIGH)\n",
    "res = cv2.bitwise_and(img,img, mask= mask)\n",
    "showImage(res, \"Ansy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Opening: The opening operation is an erosion operation followed by a dilation. \n",
    "Opening can remove small objects from the foreground (usually taken as the dark pixels) \n",
    "of an image, while not significantly changing the size of larger objects in the image. \n",
    "In other words, it is useful for removing noise.\n",
    "\n",
    "Closing: The closing operation is a dilation operation followed by an erosion. \n",
    "Closing can remove small holes in the foreground, generally smooth sections of \n",
    "the foreground, and separate objects that are touching. Therefore, it is often \n",
    "used to fill holes and small gaps.\n",
    "'''\n",
    "def detect(img, color_space=\"HSV\"):\n",
    "\n",
    "    if color_space == 'HSV':\n",
    "        color_frame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        color_ranges = {\n",
    "            \"yellow\": (np.array([15, 60, 100]), np.array([35, 255, 255])),\n",
    "            \"blue\": (np.array([110, 60, 50]), np.array([130, 255, 255])),\n",
    "            \"green\": (np.array([40, 60, 120]), np.array([80, 255, 255])),\n",
    "            # Lower range for red\n",
    "            \"red1\": (np.array([0, 60, 70]), np.array([10, 255, 255])),\n",
    "            # Upper range for red\n",
    "            \"red2\": (np.array([160, 60, 70]), np.array([180, 255, 255])),\n",
    "        }\n",
    "    elif color_space == 'Lab':\n",
    "        color_frame = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "        color_ranges = {\n",
    "            \"yellow\": (np.array([20, 110, 180]), np.array([100, 128, 255])),\n",
    "            \"blue\": (np.array([20, 80, 110]), np.array([100, 127, 150])),\n",
    "            \"green\": (np.array([20, 50, 80]), np.array([100, 128, 127])),\n",
    "            \"red\": (np.array([20, 150, 150]), np.array([60, 255, 255])),\n",
    "        }\n",
    "    elif color_space == 'YCrCB':\n",
    "        color_ranges = {\n",
    "            \"yellow\": (np.array([60, 100, 100]), np.array([100, 255, 255])),\n",
    "            \"blue\": (np.array([20, 50, 80]), np.array([100, 255, 255])),\n",
    "            \"green\": (np.array([30, 100, 60]), np.array([90, 255, 255])),\n",
    "            # Lower range for red\n",
    "            \"red1\": (np.array([0, 100, 100]), np.array([10, 255, 255])),\n",
    "            # Upper range for red\n",
    "            \"red2\": (np.array([170, 100, 100]), np.array([180, 255, 255])),\n",
    "        }\n",
    "        color_frame = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid color space. Choose 'HSV' or 'Lab'.\")\n",
    "\n",
    "    kernel = np.ones((4,4), np.uint8)\n",
    "    opening = cv2.morphologyEx(color_frame, cv2.MORPH_OPEN, kernel)\n",
    "    color_frame = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    if color_space == 'HSV' or color_space == 'YCrCB':\n",
    "        red_mask1 = cv2.inRange(color_frame, *color_ranges[\"red1\"])\n",
    "        red_mask2 = cv2.inRange(color_frame, *color_ranges[\"red2\"])\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "        color_masks = {color: cv2.inRange(color_frame, low, high) for color, (low, high) in color_ranges.items() if color not in [\"red1\", \"red2\"]}\n",
    "        color_masks[\"red\"] = red_mask  # Add the combined red mask\n",
    "    else:\n",
    "        color_masks = {color: cv2.inRange(color_frame, low, high) for color, (low, high) in color_ranges.items()}\n",
    "\n",
    "\n",
    "    contours = {color: imutils.grab_contours(cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE))\n",
    "                for color, mask in color_masks.items()}\n",
    "\n",
    "    results = {}\n",
    "    for color, cnts in contours.items():\n",
    "        largest = 0\n",
    "        second_largest = 0\n",
    "        largest_rect = (0, 0, 0, 0)\n",
    "        second_largest_rect = (0, 0, 0, 0)\n",
    "\n",
    "        for contour in cnts:\n",
    "            rect = cv2.boundingRect(contour)\n",
    "            x, y, w, h = rect\n",
    "            area = w * h\n",
    "            if area > largest:\n",
    "                largest, second_largest = area, largest\n",
    "                largest_rect, second_largest_rect = rect, largest_rect\n",
    "            elif area > second_largest:\n",
    "                second_largest = area\n",
    "                second_largest_rect = rect\n",
    "\n",
    "        results[color] = (second_largest_rect, largest_rect)\n",
    "\n",
    "    for color, ((x1, y1, w1, h1), (x2, y2, w2, h2)) in results.items():\n",
    "        cv2.rectangle(img, (x1, y1), (x1 + w1, y1 + h1), (255, 0, 0), 2)\n",
    "        cv2.rectangle(img, (x2, y2), (x2 + w2, y2 + h2), (255, 0, 0), 2)\n",
    "        cv2.putText(img, f'{color}_cube_holder', (x2, y2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "        cv2.putText(img, f'{color}_cube', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "    return results, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"test.jpg\")\n",
    "res, new_img = detect(img, \"HSV\")\n",
    "\n",
    "showImage(new_img, \"HSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: yellow and rec: ((430, 0, 6, 8), (50, 274, 38, 44))\n",
      "Rectangle: (430, 0, 6, 8)\n",
      "Rectangle: (50, 274, 38, 44)\n",
      "Color: blue and rec: ((0, 0, 0, 0), (446, 196, 55, 67))\n",
      "Rectangle: (0, 0, 0, 0)\n",
      "Rectangle: (446, 196, 55, 67)\n",
      "Color: green and rec: ((312, 194, 21, 32), (351, 44, 62, 94))\n",
      "Rectangle: (312, 194, 21, 32)\n",
      "Rectangle: (351, 44, 62, 94)\n",
      "Color: red and rec: ((0, 0, 0, 0), (0, 0, 0, 0))\n",
      "Rectangle: (0, 0, 0, 0)\n",
      "Rectangle: (0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "for color, rect in res.items():\n",
    "    print(f'Color: {color} and rec: {rect}')\n",
    "    \n",
    "    for rectagle in rect:\n",
    "        print(f'Rectangle: {rectagle}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect2(img):\n",
    "\n",
    "    # hsv = hue, saturation, value\n",
    "    hsv_frame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # specify yellow range that should be detected\n",
    "    low_yellow = np.array([15, 20, 180])\n",
    "    high_yellow = np.array([35, 255, 255])\n",
    "    yellow_mask = cv2.inRange(hsv_frame, low_yellow, high_yellow)\n",
    "    yellow = cv2.bitwise_and(img, img, mask=yellow_mask)\n",
    "    masked_img_yellow = yellow_mask.astype(np.uint8)\n",
    "\n",
    "    # specify blue range that should be detected\n",
    "    low_blue = np.array([100, 70, 80])\n",
    "    high_blue = np.array([130, 255, 255])\n",
    "    blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "    blue = cv2.bitwise_and(img, img, mask=blue_mask)\n",
    "\n",
    "    # cv2.imshow(\"Blue\", blue)\n",
    "    # cv2.imshow(\"mask\", blue_mask)\n",
    "\n",
    "    masked_img_blue = blue_mask.astype(np.uint8)\n",
    "\n",
    "    # specify red range that should be detected\n",
    "    low_red = np.array([135, 50, 80])\n",
    "    high_red = np.array([180, 255, 255])\n",
    "    red_mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "    red = cv2.bitwise_and(img, img, mask=red_mask)\n",
    "    masked_img_red = red_mask.astype(np.uint8)\n",
    "\n",
    "    # specify green range that should be detected\n",
    "    low_green = np.array([40, 30, 110])\n",
    "    high_green = np.array([80, 255, 255])\n",
    "    green_mask = cv2.inRange(hsv_frame, low_green, high_green)\n",
    "    green = cv2.bitwise_and(img, img, mask=green_mask)\n",
    "    masked_img_green = green_mask.astype(np.uint8)\n",
    "\n",
    "    # find contours in the thresholded image\n",
    "    cnts_green = cv2.findContours(\n",
    "        masked_img_green.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_green = imutils.grab_contours(cnts_green)\n",
    "\n",
    "    # find contours in the thresholded image\n",
    "    cnts_red = cv2.findContours(\n",
    "        masked_img_red.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_red = imutils.grab_contours(cnts_red)\n",
    "\n",
    "    # find contours in the thresholded image\n",
    "    cnts_yellow = cv2.findContours(\n",
    "        masked_img_yellow.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_yellow = imutils.grab_contours(cnts_yellow)\n",
    "\n",
    "    # find contours in the thresholded image\n",
    "    cnts_blue = cv2.findContours(\n",
    "        masked_img_blue.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_blue = imutils.grab_contours(cnts_blue)\n",
    "\n",
    "    # print(\"[INFO] {} unique contours found\".format(len(cnts)))\n",
    "    l_w_h = 0\n",
    "    ll_w_h = 0\n",
    "    l_rect_blue = 0, 0, 0, 0\n",
    "    l_rect_red = 0, 0, 0, 0\n",
    "    l_rect_yellow = 0, 0, 0, 0\n",
    "    l_rect_green = 0, 0, 0, 0\n",
    "\n",
    "    ll_rect_green = 0, 0, 0, 0\n",
    "    ll_rect_blue = 0, 0, 0, 0\n",
    "    ll_rect_red = 0, 0, 0, 0\n",
    "    ll_rect_yellow = 0, 0, 0, 0\n",
    "    ll_rect_green = 0, 0, 0, 0\n",
    "\n",
    "    # sometimes small particles are detected, too - filter the largest rectangle\n",
    "    for contour in cnts_green:\n",
    "        rect = cv2.boundingRect(contour)\n",
    "        x, y, w, h = rect\n",
    "        if w*h > l_w_h:\n",
    "            l_w_h = w*h\n",
    "            ll_rect_green = l_rect_green\n",
    "            l_rect_green = rect\n",
    "            continue\n",
    "        if w*h > ll_w_h: \n",
    "            ll_w_h =w*h\n",
    "            ll_rect_green = rect\n",
    "    cv2.rectangle(img, (ll_rect_green[0], ll_rect_green[1]), (ll_rect_green[0]+ll_rect_green[2], ll_rect_green[1]+ll_rect_green[3]), (255,0,0), 2)\n",
    "    cv2.rectangle(img, (l_rect_green[0], l_rect_green[1]), (l_rect_green[0]+l_rect_green[2], l_rect_green[1]+l_rect_green[3]), (255,0,0), 2)\n",
    "\n",
    "    cv2.putText(img, 'green_cube_holder', (l_rect_green[0], l_rect_green[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    cv2.putText(img, 'green_cube', (ll_rect_green[0], ll_rect_green[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "    \n",
    "    l_w_h = 0\n",
    "    ll_w_h = 0\n",
    "    for contour in cnts_blue:\n",
    "        rect = cv2.boundingRect(contour)\n",
    "        x, y, w, h = rect\n",
    "        if w*h > l_w_h:\n",
    "            l_w_h = w*h\n",
    "            ll_rect_blue = l_rect_blue\n",
    "            l_rect_blue = rect\n",
    "            continue\n",
    "        if w*h > ll_w_h: \n",
    "            ll_w_h =w*h\n",
    "            ll_rect_blue = rect\n",
    "    cv2.rectangle(img, (ll_rect_blue[0], ll_rect_blue[1]), (ll_rect_blue[0]+ll_rect_blue[2], ll_rect_blue[1]+ll_rect_blue[3]), (255,0,0), 2)\n",
    "    cv2.rectangle(img, (l_rect_blue[0], l_rect_blue[1]), (l_rect_blue[0]+l_rect_blue[2], l_rect_blue[1]+l_rect_blue[3]), (255,0,0), 2)\n",
    "\n",
    "    cv2.putText(img, 'blue_cube_holder', (l_rect_blue[0], l_rect_blue[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    cv2.putText(img, 'blue_cube', (ll_rect_blue[0], ll_rect_blue[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    \n",
    "    l_w_h = 0\n",
    "    ll_w_h = 0\n",
    "    for contour in cnts_red:\n",
    "        rect = cv2.boundingRect(contour)\n",
    "        x, y, w, h = rect\n",
    "        if w*h > l_w_h:\n",
    "            l_w_h = w*h\n",
    "            ll_rect_red = l_rect_red\n",
    "            l_rect_red = rect\n",
    "            continue\n",
    "        if w*h > ll_w_h: \n",
    "            ll_w_h =w*h\n",
    "            ll_rect_red = rect\n",
    "    cv2.rectangle(img, (ll_rect_red[0], ll_rect_red[1]), (ll_rect_red[0]+ll_rect_red[2], ll_rect_red[1]+ll_rect_red[3]), (255,0,0), 2)\n",
    "    cv2.rectangle(img, (l_rect_red[0], l_rect_red[1]), (l_rect_red[0]+l_rect_red[2], l_rect_red[1]+l_rect_red[3]), (255,0,0), 2)\n",
    "\n",
    "    cv2.putText(img, 'red_cube_holder', (l_rect_red[0], l_rect_red[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    cv2.putText(img, 'red_cube', (ll_rect_red[0], ll_rect_red[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "    \n",
    "    l_w_h = 0\n",
    "    ll_w_h = 0\n",
    "    for contour in cnts_yellow:\n",
    "        rect = cv2.boundingRect(contour)\n",
    "        x, y, w, h = rect\n",
    "        if w*h > l_w_h:\n",
    "            l_w_h = w*h\n",
    "            ll_rect_yellow = l_rect_yellow\n",
    "            l_rect_yellow = rect\n",
    "            continue\n",
    "        if w*h > ll_w_h: \n",
    "            ll_w_h =w*h\n",
    "            ll_rect_yellow = rect\n",
    "    \n",
    "    cv2.rectangle(img, (ll_rect_yellow[0], ll_rect_yellow[1]), (ll_rect_yellow[0]+ll_rect_yellow[2], ll_rect_yellow[1]+ll_rect_yellow[3]), (255,0,0), 2)\n",
    "    cv2.rectangle(img, (l_rect_yellow[0], l_rect_yellow[1]), (l_rect_yellow[0]+l_rect_yellow[2], l_rect_yellow[1]+l_rect_yellow[3]), (255,0,0), 2)\n",
    "\n",
    "    cv2.putText(img, 'yellow_cube_holder', (l_rect_yellow[0], l_rect_yellow[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    cv2.putText(img, 'yellow_cube', (ll_rect_yellow[0], ll_rect_yellow[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "    \n",
    "    color_array=(ll_rect_green, l_rect_green, ll_rect_blue, l_rect_blue,ll_rect_red, l_rect_red,ll_rect_yellow, l_rect_yellow)\n",
    "    \n",
    "        \n",
    "    #cv2.imshow(\"Masks\", img)\n",
    "    #key = cv2.waitKey(1)\n",
    "\n",
    "    return color_array, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress, new_imggg = detect2(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 164, 30, 24),\n",
       " (353, 46, 58, 90),\n",
       " (445, 195, 59, 70),\n",
       " (350, 43, 65, 97),\n",
       " (482, 78, 2, 10),\n",
       " (481, 47, 95, 74),\n",
       " (44, 280, 5, 8),\n",
       " (52, 276, 35, 41))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
